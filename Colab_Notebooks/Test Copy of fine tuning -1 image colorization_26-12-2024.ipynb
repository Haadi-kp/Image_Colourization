from google.colab import drive
drive.mount('/content/drive')
# Create the destination folder if it doesn't exist
!mkdir -p /content/datas


# Unzip files into the 'datas' folder
!unzip /content/drive/MyDrive/image_colouring/ImageNetDataset.zip -d /content/datas


import tensorflow as tf
from tensorflow import keras


# File paths for the saved models
generator_file_path = '/content/drive/MyDrive/saved_model/generator_model.h5'
discriminator_file_path = '/content/drive/MyDrive/saved_model/discriminator_model.h5'

# Load the models
generator = tf.keras.models.load_model(generator_file_path)  # Add custom_objects
discriminator = tf.keras.models.load_model(discriminator_file_path)

print("Generator and Discriminator models loaded successfully.")



# generator.compile(
#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002),
#     loss='mse',
#     metrics=['accuracy']
# )

# discriminator.compile(
#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002),
#     loss='binary_crossentropy',
#     metrics=['accuracy']
# )

import os
import numpy as np
from PIL import Image
from sklearn.model_selection import train_test_split
import tensorflow as tf

# Configuration
batch_size = 64
img_size = 120
max_folders = 50
images_per_folder = 50  # Use 50 images per folder
master_dir = '/content/datas'

# Initialize arrays for grayscale and RGB images
x = []  # Grayscale images
y = []  # RGB images

# Get and sort folder names, skipping the first 50 folders
all_folders = sorted([folder for folder in os.listdir(master_dir) if os.path.isdir(os.path.join(master_dir, folder))])
folders_to_process = all_folders[50:50 + max_folders]  # Next 25 folders

# Process each folder
for folder_name in folders_to_process:
    folder_path = os.path.join(master_dir, folder_name)
    print(f"Processing folder: {folder_name}")

    processed_images = 0  # Counter to track processed images
    for image_file in os.listdir(folder_path):
        if processed_images >= images_per_folder:  # Stop after 50 images
            break
        image_path = os.path.join(folder_path, image_file)
        try:
            # Load and preprocess the image
            rgb_image = Image.open(image_path).resize((img_size, img_size))
            rgb_array = np.asarray(rgb_image) / 255.0  # Normalize RGB

            # Convert the RGB image to grayscale
            gray_image = rgb_image.convert('L')  # Convert to grayscale
            gray_array = np.asarray(gray_image).reshape((img_size, img_size, 1)) / 255.0  # Normalize grayscale

            # Append grayscale and RGB arrays
            x.append(gray_array)
            y.append(rgb_array)

            processed_images += 1  # Increment the image counter
        except Exception as e:
            print(f"Error processing image {image_path}: {e}")

# Train-test splitting
train_x, test_x, train_y, test_y = train_test_split(np.array(x), np.array(y), test_size=0.1)

# Create tf.data.Dataset objects for training and testing
train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(batch_size).shuffle(100)
test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(batch_size)

cross_entropy = tf.keras.losses.BinaryCrossentropy()
mse = tf.keras.losses.MeanSquaredError()

def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output) - tf.random.uniform( shape=real_output.shape , maxval=0.1 ) , real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output) + tf.random.uniform( shape=fake_output.shape , maxval=0.1  ) , fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

def generator_loss(fake_output , real_y):
    real_y = tf.cast( real_y , 'float32' )
    return mse( fake_output , real_y )

generator_optimizer = tf.keras.optimizers.Adam( 0.0005 )
discriminator_optimizer = tf.keras.optimizers.Adam( 0.0005 )
# generator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, beta_1=0.5)
# discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, beta_1=0.5)

@tf.function
def train_step( input_x , real_y ):

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        # Generate an image -> G( x )
        generated_images = generator( input_x , training=True)
        # Probability that the given image is real -> D( x )
        real_output = discriminator( real_y, training=True)
        # Probability that the given image is the one generated -> D( G( x ) )
        generated_output = discriminator(generated_images, training=True)

        # L2 Loss -> || y - G(x) ||^2
        gen_loss = generator_loss( generated_images , real_y )
        # Log loss for the discriminator
        disc_loss = discriminator_loss( real_output, generated_output )

    #tf.keras.backend.print_tensor( tf.keras.backend.mean( gen_loss ) )
    #tf.keras.backend.print_tensor( gen_loss + disc_loss )

    # Compute the gradients
    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    # Optimize with Adam
    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

    return gen_loss, disc_loss

num_epochs = 50

for epoch in range(num_epochs):
    print(f"Epoch {epoch + 1}/{num_epochs}")
    iteration = 0  # Counter for iterations

    # Iterate through the dataset
    for input_x, real_y in train_dataset:
        # Perform a training step
        gen_loss, disc_loss = train_step(input_x, real_y)

        # Log every 20th iteration
        if iteration % 10 == 0:
            print(f"Iteration {iteration}, Generator Loss: {gen_loss:.4f}, Discriminator Loss: {disc_loss:.4f}")
        iteration += 1




# # Ensure the generator is compiled before saving
# generator.compile(
#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002),
#     loss='mse',  # Use Mean Squared Error or a loss suitable for your task
#     metrics=['accuracy']
# )

# Save the generator model to a single HDF5 file
generator_file_path = '/content/drive/MyDrive/saved_model/finetune_generator_model.h5'
generator.save(generator_file_path)
print(f"Generator model saved to {generator_file_path}")

# # Ensure the discriminator is compiled before saving
# discriminator.compile(
#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002),
#     loss='binary_crossentropy',  # Use Binary Crossentropy or a loss suitable for your task
#     metrics=['accuracy']
# )

# Save the discriminator model to a single HDF5 file
discriminator_file_path = '/content/drive/MyDrive/saved_model/finetune_discriminator_model.h5'
discriminator.save(discriminator_file_path)
print(f"Discriminator model saved to {discriminator_file_path}")

# import tensorflow as tf

# # File paths for the saved models
# generator_file_path = '/content/drive/MyDrive/saved_model/finetune_generator_model.h5'
# discriminator_file_path = '/content/drive/MyDrive/saved_model/finetune_discriminator_model.h5'

# # Load the models
# generator = tf.keras.models.load_model(generator_file_path)  # Add custom_objects
# discriminator = tf.keras.models.load_model(discriminator_file_path)

# print("Generator and Discriminator models loaded successfully.")



from io import BytesIO
import requests
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt


# # Ensure generator model is initialized

# # Load trained weights if available
# # generator.load_weights("path_to_model_weights.h5")

# Visualize results for testing data
for i in range(len(test_x)):
    try:
        # Prepare grayscale input
        test_image = test_x[i].reshape(1, 120, 120, 1)  # Reshape to match model input

        # Generate colorized output
        colorized_output = generator(test_image).numpy()

        # Visualize the input, colorized output, and ground truth
        plt.figure(figsize=(15, 5))

        # Grayscale Input
        or_image = plt.subplot(1, 3, 1)
        or_image.set_title('Grayscale Input', fontsize=16)
        plt.imshow(test_x[i].reshape((120, 120)), cmap='gray')
        plt.axis('off')

        # Colorized Output
        in_image = plt.subplot(1, 3, 2)
        colorized_img = Image.fromarray((colorized_output[0] * 255).astype('uint8')).resize((1024, 1024))
        in_image.set_title('Colorized Output', fontsize=16)
        plt.imshow(colorized_img)
        plt.axis('off')

        # Ground Truth
        ou_image = plt.subplot(1, 3, 3)
        ground_truth_img = Image.fromarray((test_y[i] * 255).astype('uint8')).resize((1024, 1024))
        ou_image.set_title('Ground Truth', fontsize=16)
        plt.imshow(ground_truth_img)
        plt.axis('off')

        plt.show()

    except Exception as e:
        print(f"Error processing image {i + 1}: {e}")



# Define a function to download and process an image from a URL
def process_image_from_url(url, target_size=(120, 120)):
    response = requests.get(url)
    if response.status_code == 200:
        # Open the image from the response
        image = Image.open(BytesIO(response.content)).convert("L")  # Convert to grayscale
        # Resize to the model's expected input size
        image = image.resize(target_size)
        # Normalize the image
        image_array = np.asarray(image) / 255.0
        # Add batch and channel dimensions
        return image_array.reshape(1, target_size[0], target_size[1], 1)
    else:
        raise Exception(f"Failed to fetch image from URL: {response.status_code}")

# List of image URLs
image_urls = [
    "https://images.pexels.com/photos/346529/pexels-photo-346529.jpeg?cs=srgb&dl=pexels-bri-schneiter-28802-346529.jpg&fm=jpg",
    "https://media.istockphoto.com/id/517188688/photo/mountain-landscape.jpg?s=612x612&w=0&k=20&c=A63koPKaCyIwQWOTFBRWXj_PwCrR4cEoOw2S9Q7yVl8=",
    "https://images.pexels.com/photos/170811/pexels-photo-170811.jpeg?cs=srgb&dl=pexels-mikebirdy-170811.jpg&fm=jpg",
    "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSzrMllu8JUuu4lUfJ21cmtXbQZXiN2oK_Z0M5UZPhM8D8Yek9KZPJnWst-bm7ml2G_ydE&usqp=CAU"
    # Add more image URLs here
]

# Iterate over the image URLs and test the model
for i, url in enumerate(image_urls):
    try:
        # Process the image
        test_image = process_image_from_url(url)

        # Generate colorized output
        colorized_output = generator(test_image).numpy()

        # Visualize the input and output
        plt.figure(figsize=(10, 10))

        # Grayscale Input
        or_image = plt.subplot(1, 3, 1)
        or_image.set_title('Grayscale Input', fontsize=16)
        plt.imshow(test_image[0].reshape((120, 120)), cmap='gray')

        # Colorized Output
        in_image = plt.subplot(1, 3, 2)
        output_image = Image.fromarray((colorized_output[0] * 255).astype('uint8')).resize((1024, 1024))
        in_image.set_title('Colorized Output', fontsize=16)
        plt.imshow(output_image)

        plt.show()

    except Exception as e:
        print(f"Error processing image {i + 1}: {e}")

